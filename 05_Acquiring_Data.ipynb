{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Acquiring Data.ipynb","provenance":[{"file_id":"1AoStM6JybQLj-JIRhSmZbeE7Tv4BSk-I","timestamp":1617207753248}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/02_data/04_acquiring_data/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"OzLFRcmOksBr"},"source":["#### Copyright 2020 Google LLC."]},{"cell_type":"code","metadata":{"id":"3tZgyec1kaQy"},"source":["# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PyPyGxHwkwdy"},"source":["# Acquiring Data"]},{"cell_type":"markdown","metadata":{"id":"KnIZ7zaIk1Jp"},"source":["The datasets we have worked with so far have all been small enough that we have directly typed them in our code blocks. In reality, you'll need to bring in your data from an outside source.\n","\n","This can be done in many ways. We'll explore a few in this lab and, we will also mention some methods that are out of scope for this course but often seen in the wild."]},{"cell_type":"markdown","metadata":{"id":"hEF_UYMsleDY"},"source":["## Uploading Data"]},{"cell_type":"markdown","metadata":{"id":"nkTOvJPmlgpJ"},"source":["If you have the data that you want to work with on your computer, you can work with it locally using [Python](http://python.org), [Jupyter](https://jupyter.org/), and/or many other tools. If you want to work with that data in Colab, you'll need to upload the data to Colab since Colab executes code on a virtual machine in the cloud, not locally on your computer.\n","\n","The first step of uploading data is having the data on your local machine.\n","\n","For this example we will use the famous [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). There are many copies of this dataset on the internet. We'll use the [version hosted by the University of California Irvine](https://archive.ics.uci.edu/ml/datasets/Iris).\n","\n","The direct link to the dataset is [https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data).\n","\n","**Download `iris.data` now.**\n","\n","Once you have the data downloaded, you can upload the file to this Colab environment. To do that:\n","\n","1. Click on the folder icon on the left of the Colab interface. This opens the 'Files' sidebar.\n","1. At the top of the sidebar there is an 'Upload' link. Click the link in order to open a file selctor.\n","1. Through the selector, find the `iris.data` file that you just downloaded.\n","1. Click 'Open' or 'OK' to confirm the upload.\n","\n","You will see a warning about files not being saved. This is because the file is stored on a virtual machine in the cloud, and when that machine is turned off, all files in it are lost. For classes like this you should be fine. For longer projects or long-running model trainings, there are other ways and places to store your files. We'll get to those later in the course.\n","\n","Let's see if you uploaded the file successfully.\n","\n","**Run the code block below**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"vmb-D-kzri28","executionInfo":{"status":"error","timestamp":1617207829036,"user_tz":-480,"elapsed":2849,"user":{"displayName":"Tiara Yania Ifani Lakita M2082041","photoUrl":"","userId":"17344587781637222050"}},"outputId":"4a076d7f-3552-4733-d78b-5ab61bd9b853"},"source":["import pandas as pd\n","\n","column_names = [\n","  'sepal length',\n","  'sepal width',\n","  'petal length',\n","  'petal width',\n","  'class'\n","]\n","\n","pd.read_csv('iris.data', names=column_names)"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b8dc0961030b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iris.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iris.data'"]}]},{"cell_type":"markdown","metadata":{"id":"Vjh_Fy1Bronb"},"source":["You should see a `DataFrame` containing information about iris flowers.\n","\n","If you get an error, you likely uploaded the wrong file or uploaded the file to the wrong location.\n","\n","By default Colab works in the `/content/` folder of the virtual machine. Most of the time this is invisible to you. However, when you uploaded the file, you might have hit the 'Parent Directory' link instead of the 'Upload' link since they are close to each other and both have \"up arrow\" icons. If you see a long list of folders instead of a single `sample_data` folder in the files list, then you hit the 'Parent Directory' button. Unfortunately, the only way to redirect uploads to the correct folder is to restart your runtime."]},{"cell_type":"markdown","metadata":{"id":"WlLpm2Jmuq46"},"source":["## Downloading With Python"]},{"cell_type":"markdown","metadata":{"id":"W8iw28Imuw_9"},"source":["If your data is hosted online, you can use Python to directly download the data and bypass the download/upload cycle mentioned in the last section.\n","\n","One way to do this is to use the [`urllib.request`](https://docs.python.org/3/library/urllib.request.html) library's [`urlretrieve`](https://docs.python.org/3/library/urllib.request.html#urllib.request.urlretrieve) method.\n","\n","In the example below we request the `iris.names` file from UCI and then list the directory where it was downloaded."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MgfvECEvQT8","executionInfo":{"status":"ok","timestamp":1617207938871,"user_tz":-480,"elapsed":1082,"user":{"displayName":"Tiara Yania Ifani Lakita M2082041","photoUrl":"","userId":"17344587781637222050"}},"outputId":"527b98ae-71e1-425e-95e2-48c3ded707a2"},"source":["import urllib.request\n","import os\n","\n","urllib.request.urlretrieve(\n","    'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.names',\n","    'iris.names')\n","\n","os.listdir()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'iris.names', 'sample_data']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"_GkeI7jAw8qN"},"source":["## Downloading With Pandas"]},{"cell_type":"markdown","metadata":{"id":"m5umC0gNxP-Z"},"source":["It is possible to download data directly into a Pandas `DataFrame`. We have used `read_csv` in previous labs to load files from disk. If you pass `read_csv`, a URL it will pull data from the internet and load that data into a `DataFrame` in one shot."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"AKCn7epnwLVH","executionInfo":{"status":"ok","timestamp":1617208011101,"user_tz":-480,"elapsed":1528,"user":{"displayName":"Tiara Yania Ifani Lakita M2082041","photoUrl":"","userId":"17344587781637222050"}},"outputId":"8cd7fddd-397c-4ec0-e152-40f925e326be"},"source":["import pandas as pd\n","\n","column_names = [\n","  'sepal length',\n","  'sepal width',\n","  'petal length',\n","  'petal width',\n","  'class'\n","]\n","\n","url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n","\n","pd.read_csv(url, names=column_names)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length</th>\n","      <th>sepal width</th>\n","      <th>petal length</th>\n","      <th>petal width</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 5 columns</p>\n","</div>"],"text/plain":["     sepal length  sepal width  petal length  petal width           class\n","0             5.1          3.5           1.4          0.2     Iris-setosa\n","1             4.9          3.0           1.4          0.2     Iris-setosa\n","2             4.7          3.2           1.3          0.2     Iris-setosa\n","3             4.6          3.1           1.5          0.2     Iris-setosa\n","4             5.0          3.6           1.4          0.2     Iris-setosa\n","..            ...          ...           ...          ...             ...\n","145           6.7          3.0           5.2          2.3  Iris-virginica\n","146           6.3          2.5           5.0          1.9  Iris-virginica\n","147           6.5          3.0           5.2          2.0  Iris-virginica\n","148           6.2          3.4           5.4          2.3  Iris-virginica\n","149           5.9          3.0           5.1          1.8  Iris-virginica\n","\n","[150 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"QCf9PZcExl1_"},"source":["## Kaggle Data"]},{"cell_type":"markdown","metadata":{"id":"Ohm8LanNxnqi"},"source":["Kaggle is a popular machine learning and data science educational playground. There are many interesting datasets hosted on [Kaggle's datasets page](https://www.kaggle.com/datasets).\n","\n","If you [navigate to a dataset](https://www.kaggle.com/joshmcadams/oranges-vs-grapefruit) you won't be able to download it until you create a Kaggle account.\n","\n","We'll be using Kaggle in this course. Even outside of the course, Kaggle is a great place to learn and experiment with machine learning and data science, all while building your public machine learning and data science resume.\n","\n","**Log in to Kaggle now. Create a new account if you need to.**\n","\n","At this point you should have a Kaggle account. You can now download [a dataset](https://www.kaggle.com/joshmcadams/oranges-vs-grapefruit) by clicking on the 'Download' link at the top of the information page for the dataset.\n","\n","If you download the [Oranges vs. Grapefruit](https://www.kaggle.com/joshmcadams/oranges-vs-grapefruit) dataset, you should now have a file called `oranges-vs-grapefruit.zip` on your computer.\n","\n","**Upload `oranges-vs-grapefruit.zip` to this lab.**\n","\n","Now that you have uploaded `oranges-vs-grapefruit.zip`, we can load it into a `DataFrame`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"yLT5gyw5zS02","outputId":"ba4f7f7a-79b9-4935-db0f-83d3024fed74"},"source":["import pandas as pd\n","\n","pd.read_csv('oranges-vs-grapefruit.zip')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>diameter</th>\n","      <th>weight</th>\n","      <th>red</th>\n","      <th>green</th>\n","      <th>blue</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>orange</td>\n","      <td>2.96</td>\n","      <td>86.76</td>\n","      <td>172</td>\n","      <td>85</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>orange</td>\n","      <td>3.91</td>\n","      <td>88.05</td>\n","      <td>166</td>\n","      <td>78</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>orange</td>\n","      <td>4.42</td>\n","      <td>95.17</td>\n","      <td>156</td>\n","      <td>81</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>orange</td>\n","      <td>4.47</td>\n","      <td>95.60</td>\n","      <td>163</td>\n","      <td>81</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>orange</td>\n","      <td>4.48</td>\n","      <td>95.76</td>\n","      <td>161</td>\n","      <td>72</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>grapefruit</td>\n","      <td>15.35</td>\n","      <td>253.89</td>\n","      <td>149</td>\n","      <td>77</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>grapefruit</td>\n","      <td>15.41</td>\n","      <td>254.67</td>\n","      <td>148</td>\n","      <td>68</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>grapefruit</td>\n","      <td>15.59</td>\n","      <td>256.50</td>\n","      <td>168</td>\n","      <td>82</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>grapefruit</td>\n","      <td>15.92</td>\n","      <td>260.14</td>\n","      <td>142</td>\n","      <td>72</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>grapefruit</td>\n","      <td>16.45</td>\n","      <td>261.51</td>\n","      <td>152</td>\n","      <td>74</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 6 columns</p>\n","</div>"],"text/plain":["            name  diameter  weight  red  green  blue\n","0         orange      2.96   86.76  172     85     2\n","1         orange      3.91   88.05  166     78     3\n","2         orange      4.42   95.17  156     81     2\n","3         orange      4.47   95.60  163     81     4\n","4         orange      4.48   95.76  161     72     9\n","...          ...       ...     ...  ...    ...   ...\n","9995  grapefruit     15.35  253.89  149     77    20\n","9996  grapefruit     15.41  254.67  148     68     7\n","9997  grapefruit     15.59  256.50  168     82    20\n","9998  grapefruit     15.92  260.14  142     72    11\n","9999  grapefruit     16.45  261.51  152     74     2\n","\n","[10000 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"PBCwLg-Ozheo"},"source":["Notice that the file that we loaded was `oranges-vs-grapefruit.zip`, which is a zip file, not a csv file. Zip files are 'compressed' files. We do this to save space. However, if you were to open `oranges-vs-grapefruit.zip` in a text editor, you wouldn't be able to read it. Lucky for us, `read_csv` knows what to do when it receives a compressed file."]},{"cell_type":"markdown","metadata":{"id":"JmNyBu5k0PgP"},"source":["Sometimes we will want to decompress a file before creating a `DataFrame`. Zip files can contain more than one file, so we might need to unzip our files and then load them individually into `DataFrame` objects.\n","\n","To do this we use the `zipfile` library.\n","\n","In the example below, we open the zip file and then extract all of the contained files into the current directory. We then list the directory and see that we now have a `citrus.csv` file, which is the uncompressed contents of `oranges-vs-grapefruit.zip`. This csv can then be loaded into a `DataFrame` directly."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119},"id":"w-3EWuA1z7ay","outputId":"7391b0b0-d732-459f-b5c2-e916c5506b55"},"source":["import zipfile\n","import os\n","\n","with zipfile.ZipFile('oranges-vs-grapefruit.zip','r') as z:\n","  z.extractall('./')\n","\n","os.listdir()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config',\n"," 'oranges-vs-grapefruit.zip',\n"," 'iris.data',\n"," 'iris.names',\n"," 'citrus.csv',\n"," 'sample_data']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"oWRsl7N30-Km"},"source":["Zip is one of many file compression formats, and it is actually more than just a compression format. Remember when we mentioned above that a zip file might contain multiple files? The combining of one or more files is known as archiving. The reduction in size of files is known as compression. Zip is actually an archiving and compression algorithm.\n","\n","You can find a list of similar types of algorithms [on Wikipedia](https://en.wikipedia.org/wiki/List_of_archive_formats)."]},{"cell_type":"markdown","metadata":{"id":"1eBUwkGZ1qnW"},"source":["### Direct Downloads"]},{"cell_type":"markdown","metadata":{"id":"KCl0OpHT1v8M"},"source":["So far, we've been able to download data from Kaggle and then upload it to Colab. This involves downloading the entire dataset from Kaggle's servers onto your local machine and then uploading that dataset to the Colab server to actually process the data. For small datasets, this is reasonable. But for large datasets, this can quickly become a burden on your network connection and your device's storage space.\n","\n","Kaggle offers an [API](https://github.com/Kaggle/kaggle-api) that comes with a command line program that can help you download files directly from Kaggle to Colab, skipping over your local machine entirely."]},{"cell_type":"markdown","metadata":{"id":"D3IrHnuS2LxO"},"source":["#### Credentials"]},{"cell_type":"markdown","metadata":{"id":"ymODi7Hz2dtE"},"source":["In order to use the API, you'll need to \"log in\" to Kaggle. This is done using [API credentials](https://github.com/Kaggle/kaggle-api#api-credentials) in the form of an API token.\n","\n","To do that:\n","\n","1. Navigate to the 'Account' tab of your user profile in Kaggle at `https://www.kaggle.com/<username>/account`.\n","1. Click the \"Create New API Token\" button. This will download a `kaggle.json` file containing your API credentials\n","1. Upload the `kaggle.json` file to this lab.\n","\n","**Warning: Keep your `kaggle.json` private! It contains information that will allow people to authenticate into Kaggle using your user account.**\n","\n","At this point you should have a `kaggle.json` file in the file list on the left. We can now download a dataset using the `kaggle` command and `datasets` subcommand:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"MlR0BhcL7fOK","outputId":"5b40387e-f47b-47b5-f5c5-f596a81502a5"},"source":["! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download joshmcadams/oranges-vs-grapefruit"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n","oranges-vs-grapefruit.zip: Skipping, found more recently modified local copy (use --force to force download)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zO0x1RZS-E-k"},"source":["You should see text similar to:\n","\n","```\n","Downloading oranges-vs-grapefruit.zip to /content\n","  0% 0.00/61.2k [00:00<?, ?B/s]\n","100% 61.2k/61.2k [00:00<00:00, 23.1MB/s]\n","```\n","\n","If you do, then you successfully downloaded the dataset!\n","\n","You might have also seen a warning like this:\n","\n","```\n","Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n","```\n","\n","If so, it means that the `kaggle.json` file is readable by people other than you. This is probably okay since you are on a virtual machine by yourself. If you do want to fix the warning, run `chmod` as instructed."]},{"cell_type":"code","metadata":{"id":"Dv_01Ph4-cuo"},"source":["! chmod 600 kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bq22us4ZAKuc"},"source":["You might also be wondering what that `KAGGLE_CONFIG_DIR=/content/` in front of the `kaggle` command was.\n","\n","This is telling `kaggle` where to find your `kaggle.json` file. `kaggle` expects the file to be in `~/.kaggle/`. Since we didn't upload it there, `kaggle` can't find `kaggle.json` without us leading it to the correct folder.\n","\n","If you want to not have to do this, move `kaggle.json`."]},{"cell_type":"markdown","metadata":{"id":"yLTyib-S5Tcr"},"source":["First make sure the directory exists."]},{"cell_type":"code","metadata":{"id":"UyzQyfhJ5W7i"},"source":["! ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eU0tGSrF5aU9"},"source":["And then move the file."]},{"cell_type":"code","metadata":{"id":"8WUEnObbAmoU"},"source":["! mv kaggle.json ~/.kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4JfmzwIZA0mY"},"source":["Now you can run the `kaggle` command without having to set the configuration directory."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"5lAvVVC-A4sQ","outputId":"b3121e36-e706-421e-c59a-914763c7bb42"},"source":["! kaggle datasets download joshmcadams/oranges-vs-grapefruit"],"execution_count":null,"outputs":[{"output_type":"stream","text":["oranges-vs-grapefruit.zip: Skipping, found more recently modified local copy (use --force to force download)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ON00-WJMA8Rf"},"source":["Note that you'll have to repeat this process every time your virtual machine resets. The setup will live through reloads though.\n","\n","Keep a copy of your `kaggle.json` file on your local machine. Then, when you need to load your credentials into a colab, just:\n","\n","1. Upload `kaggle.json`\n","1. Create a code block and run `! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'`"]},{"cell_type":"markdown","metadata":{"id":"JbZ9rcZnCvEX"},"source":["## Other Data Acquisition Methods\n","\n","### Databases\n","\n","It is possible to interact with databases directly from Python and therefore from Colab and other notebook environments. Python has a standard [database API](https://www.python.org/dev/peps/pep-0249/) and [many toolkits](https://docs.python-guide.org/scenarios/db/) that make interacting with databases easier.\n","\n","If your data is stored in a database, you'll need to work with a database administrator to get access credentials and to understand the data and how it is stored.\n","\n","### APIs\n","\n","Data can also be accessed by application programming interface (API). APIs provide a way for you to write Python code that interacts with another system in a well defined way.\n","\n","For example, [Twitter](http://twitter.com) has an [API](https://developer.twitter.com/en/docs) that allows you to work with tweets. There are even abstraction layers like [Tweepy](https://www.tweepy.org/) that make working with the API even easier.\n","\n","Every system has their own API with different methods and calling patterns. You'll hear terms like REST, SOAP, JSON and XML thrown around when talking about specific APIs."]},{"cell_type":"markdown","metadata":{"id":"DGxDUx3OJqL_"},"source":["# Exercises"]},{"cell_type":"markdown","metadata":{"id":"1SPEtc_JJvOE"},"source":["## Exercise 1: Direct Download"]},{"cell_type":"markdown","metadata":{"id":"fpbB1R76V9ov"},"source":["Use Python to directly download the `bridges.data.version2` data file from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/bridges/). Load the data into a Pandas `DataFrame` and `.describe()` that `DataFrame`."]},{"cell_type":"markdown","metadata":{"id":"jcsltQV2WPYK"},"source":["**Student Solution**"]},{"cell_type":"code","metadata":{"id":"D1hH7ys5WSuX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617208723458,"user_tz":-480,"elapsed":2560,"user":{"displayName":"Tiara Yania Ifani Lakita M2082041","photoUrl":"","userId":"17344587781637222050"}},"outputId":"1ca9c25c-3797-478b-cc26-88b283f0307b"},"source":["# Your code goes here\n","import urllib.request\n","import os\n","\n","urllib.request.urlretrieve(\n","    'https://archive.ics.uci.edu/ml/machine-learning-databases/bridges/',\n","    'bridges.names')\n","\n","\n","\n"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'bridges.names', 'iris.names', 'sample_data']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"-Bl60nTgWU0p"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"J6TBtSkRXJ-z"},"source":["## Exercise 2: Kaggle Download"]},{"cell_type":"markdown","metadata":{"id":"tGdKCj1MXOqq"},"source":["Use the Kaggle API to download [a dataset containing avocado prices in the US](https://www.kaggle.com/neuromusic/avocado-prices). Load the data into a Pandas `DataFrame` and describe the `DataFrame`."]},{"cell_type":"markdown","metadata":{"id":"yG1zOTwwYIWl"},"source":["**Student Solution**"]},{"cell_type":"code","metadata":{"id":"AQFN17NbYKtr"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DEEHtsplYMmn"},"source":["---"]}]}