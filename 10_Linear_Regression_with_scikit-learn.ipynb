{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Linear Regression with scikit-learn.ipynb","private_outputs":true,"provenance":[{"file_id":"1dnxV5E8rDUvQnb8udU95QyZ_4_jhj9H5","timestamp":1617006161355},{"file_id":"1B_JlPBXHp-pnrgr8yadPl3TuFKdC2XxE","timestamp":1616999216881}],"collapsed_sections":["copyright"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/03_regression/02_regression_in_sklearn/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"copyright"},"source":["#### Copyright 2020 Google LLC."]},{"cell_type":"code","metadata":{"id":"GTcSKOCAomf-"},"source":["# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lsn0Av7YmMza"},"source":["# Linear Regression With `scikit-learn`"]},{"cell_type":"markdown","metadata":{"id":"Lsn0Ag7YmMza"},"source":["We have learned about linear regression in theory. Now let's put our newly-acquired skills into practice! In this Colab we will create multiple linear regression models using the scikit-learn toolkit."]},{"cell_type":"markdown","metadata":{"id":"VWTTVoS4OoQ2"},"source":["# Creating a Dataset\n","\n","In this Colab we will explore different methods of applying linear regression to a dataset. If the dataset is small enough, the coefficients of a linear regression can be calculated via a simple equation. If the dataset is large, we need to use computing algorithms such as sampling and batching to calculate the coefficients.\n","\n","But before we get started, let's create some sample data to perform our regression on. The code below creates 1000 data points. The x-coordinates are called `coffee`, and the y-coordinates are called `energy`. So this regression is trying to predict a person's energy based on coffee intake."]},{"cell_type":"code","metadata":{"id":"6_TyEuBi_qul"},"source":["import numpy as np\n","\n","np.random.seed(213)\n","\n","# The size of the dataset that we'll be using to perform our linear regression.\n","DATA_SET_SIZE = 1000\n","\n","# The maximum value of the x coordinate. The range of values of X will be\n","# (0, X_MAX).\n","X_MAX = 5\n","\n","# The y-intercept and slope are values that we'll be trying to predict via\n","# linear regression.\n","INTERCEPT = 4\n","SLOPE = 3\n","\n","# Generate the x-coordinates (coffee intake) for our dataset.\n","coffee = X_MAX * np.random.rand(DATA_SET_SIZE, 1)\n","\n","# Generate the y-coordinates (energy level) for our dataset using the linear\n","# equation y = mx + b.\n","energy = SLOPE * coffee + INTERCEPT"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cAsf4qWOSQfP"},"source":["Let's take a look at the dataset that was just generated."]},{"cell_type":"code","metadata":{"id":"QcnLIrlBRWS5"},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","plt.plot(coffee, energy, 'b.')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9_bV-puRYsM"},"source":["The dataset does indeed have an $x$ range from 0 to the max $x$-value of 5. Notice that the $y$-intercept and slope match our seeded values.\n","\n","This dataset looks nothing like what we'd see in the real world, though. It would be trivial to fit a line to the data as is; the data is already a straight line. Let's add a little randomness to the data to make it more realistic."]},{"cell_type":"code","metadata":{"id":"hIidIGmLR2QG"},"source":["energy = energy + 2 * np.random.randn(DATA_SET_SIZE, 1)\n","\n","plt.plot(coffee, energy, 'b.')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_teA7dekSCbu"},"source":["That's much better! There is still a linear trend to the data, but there is much more noise."]},{"cell_type":"markdown","metadata":{"id":"pH3KFfPAdROS"},"source":["# Running the Regression\n","\n","scikit-learn performs linear regression in its `LinearRegression` module."]},{"cell_type":"code","metadata":{"id":"372l9BTOFD09"},"source":["from sklearn.linear_model import LinearRegression\n","\n","lin_reg = LinearRegression()\n","lin_reg.fit(coffee, energy)\n","lin_reg.coef_, lin_reg.intercept_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZDO1af98ehT2"},"source":["Not bad! The random noise we added to the data prevented us from exactly predicting the slope and intercept, but our calculations were pretty close.\n","\n","We can use this slope and intercept to predict new $y$-values given some $x$-values."]},{"cell_type":"code","metadata":{"id":"cCBGwUFlFQf8"},"source":["coffee_ = np.array([[0.34], [1.65], [2.45], [3.78], [4.56]])\n","\n","energy_predict = lin_reg.predict(coffee_)\n","energy_predict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79D5EP8CfEZ6"},"source":["plt.plot(coffee, energy, 'b.')\n","plt.plot(coffee_, energy_predict, 'r.')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2k_FnFl9fTVR"},"source":["And we can use two extreme $x$-values 0 and `X_MAX` to draw the regression line."]},{"cell_type":"code","metadata":{"id":"N1IdQ92Yfa64"},"source":["coffee_ = np.array([[0.0], [X_MAX]])\n","energy_predict = lin_reg.predict(coffee_)\n","\n","plt.plot(coffee, energy, 'b.')\n","plt.plot(coffee_, energy_predict, 'r-')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-IbhNb9sfoXc"},"source":["# Stochastic Gradient Descent\n","\n","It is not always practical to run a linear regression using the entire training data set. For cases where training using the entire set is impractical, the stochastic gradient descent method can be used. In scikit-learn this is implemented via the `SGDRegressor`."]},{"cell_type":"code","metadata":{"id":"_1ad3bCyHFHY"},"source":["from sklearn.linear_model import SGDRegressor\n","\n","# Create a new Stochastic Gradient Descent regressor.\n","sgd_reg = SGDRegressor()\n","\n","# Fit the model.\n","sgd_reg.fit(coffee, energy.ravel())\n","\n","# Display the slope and intercept.\n","sgd_reg.coef_, sgd_reg.intercept_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HiPCUcIog3Tv"},"source":["You might notice that the slope and intercept aren't as accurate as what we were getting when processing the entire dataset. This is because the SGDRegressor is only using a subset of the training data."]},{"cell_type":"markdown","metadata":{"id":"6070sBV2hGwZ"},"source":["Let's compare the regression lines calculated by the full linear regressor and the SGD one."]},{"cell_type":"code","metadata":{"id":"v0tqrFIlhO4f"},"source":["coffee_ = np.array([[0.0], [5.0]])\n","\n","lin_predict = lin_reg.predict(coffee_)\n","sgd_predict = sgd_reg.predict(coffee_)\n","\n","plt.plot(coffee, energy, 'b.')\n","plt.plot(coffee_, lin_predict, 'r-')\n","plt.plot(coffee_, sgd_predict, 'g-')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BM6d6zJdtS0F"},"source":["It might be hard to see, but the red and green lines are *almost* the same but not quite."]},{"cell_type":"markdown","metadata":{"id":"IYeviiuNi_Ut"},"source":["### Challenge: Regressor Parameters\n","\n","The SGDRegressor has many parameters that can be tuned. Out of the box, our regressor didn't do that well. Let's see if we can tune some of the parameters of the regressor to get its predicted values for the slope and intercept closer to those we predicted using the entire dataset.\n","\n","Check out the [SGDRegressor documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html) and look over the parameters available. Pay special attention to parameters related to learning rate and iterations over the data. See if you can tweak the parameters to get within some threshold `EPISLON` of the calculated values below."]},{"cell_type":"code","metadata":{"id":"Cszel2xOhsXm"},"source":["import numpy as np\n","from sklearn.linear_model import SGDRegressor\n","\n","np.random.seed(21)\n","\n","# Initialize the dataset attributes.\n","DATA_SET_SIZE = 1000\n","X_MAX = 5\n","INTERCEPT = 4\n","SLOPE = 3\n","\n","# Generate the randomized dataset.\n","coffee = X_MAX * np.random.rand(DATA_SET_SIZE, 1)\n","energy = SLOPE * coffee + INTERCEPT + 2 * np.random.randn(DATA_SET_SIZE, 1)\n","\n","sgd_reg = SGDRegressor(\n","    # TODO(you): Update the parameters to SGDRegressor.\n","    )\n","\n","# Fit the model.\n","sgd_reg.fit(coffee, energy.ravel())\n","\n","EPSILON = 0.05\n","\n","print(sgd_reg.coef_, sgd_reg.intercept_)\n","if abs(SLOPE - sgd_reg.coef_) < EPSILON and abs(INTERCEPT - sgd_reg.intercept_) < EPSILON:\n","  print(\"You win!\")\n","else:\n","  print(\"Try again :(\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0KM7txB7CZXL"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"TftzlfnrS9jp"},"source":["# Optional: The Normal Equation\n","\n","If the dataset being processed is small enough, then the slope and $y$-intercept of the regression line can be calculated in-memory exactly. The matrix normal equation can easily be written in NumPy, as seen below."]},{"cell_type":"code","metadata":{"id":"6dHn3z3dC0R3"},"source":["# x is an Nx1 matrix containing our x-values. The first step in calculating the\n","# normal equation is to create an Nx2 matrix where each \"row\" has the value 1\n","# and the x value.\n","coffee_ = np.c_[np.ones((DATA_SET_SIZE, 1)), coffee]\n","\n","norm = np.linalg.inv(coffee_.T.dot(coffee_)).dot(coffee_.T).dot(energy)\n","\n","calculated_intercept = norm[0][0]\n","calculated_slope = norm[1][0]\n","\n","print(\"Calculated slope {} vs actual {}\".format(calculated_slope, SLOPE))\n","print(\"Calculated intercept {} vs actual {}\".format(calculated_intercept,\n","                                                    INTERCEPT))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H0pdPAEisg0D"},"source":["Notice that these values are the same as scikit-learn calculated above.\n","\n","We can now use these values to make predictions."]},{"cell_type":"code","metadata":{"id":"8w9L1n4tD3Ol"},"source":["# Create a (5,1) matrix containing values to make predictions on.\n","coffee_ = np.array([[0.34], [1.65], [2.45], [3.78], [4.56]])\n","\n","# Convert the matrix to a (5, 2) matrix with ones in the first column\n","# in order to perform a dot-product against the calculated slope and\n","# intercept.\n","coffee_predict = np.c_[np.ones((5, 1)), coffee_]\n","\n","# Make the predictions.\n","energy_predict = coffee_predict.dot(norm)\n","\n","# Plot the original data as blue dots.\n","plt.plot(coffee, energy, 'b.')\n","\n","# Plot the predictions as red dots.\n","plt.plot(coffee_, energy_predict, 'r.')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r2dvyzHEYLOm"},"source":["To plot the calculated line as we did for the scikit-learn regression, we can just plug in 0 and 5 (`X_MAX`) to the equation."]},{"cell_type":"code","metadata":{"id":"U9g-KRzoYUpH"},"source":["coffee_ = np.array([[0.0], [X_MAX]])\n","coffee_predict = np.c_[np.ones((2,1)), coffee_]\n","energy_predict = coffee_predict.dot(norm)\n","\n","plt.plot(coffee, energy, 'b.')\n","plt.plot(coffee_, energy_predict, 'r-')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2nqG8-MEc1SL"},"source":["### Challenge: Pseudoinverse\n","\n","It turns out that the math operations used to calculate the Normal Equation are quite expensive. We'll explore other methods of performing a linear regression soon, but there is a purely mathematical optimization that has been discovered. The equation uses the **pseudoinverse** of the input matrix to predict $y$.\n","\n","Find the NumPy function that calculates the pseudoinverse of a matrix, and then use that function to write a more optimal method for finding the slope and intercept for a linear regression."]},{"cell_type":"code","metadata":{"id":"0ANUfb9xE412"},"source":["import numpy as np\n","\n","np.random.seed(21)\n","\n","# Initialize the dataset attributes.\n","DATA_SET_SIZE = 1000\n","X_MAX = 5\n","INTERCEPT = 4\n","SLOPE = 3\n","\n","# Generate the dataset.\n","coffee = X_MAX * np.random.rand(DATA_SET_SIZE, 1)\n","energy = SLOPE * coffee + INTERCEPT\n","\n","# Create the matrix.\n","coffee_ = np.c_[np.ones((DATA_SET_SIZE, 1)), coffee]\n","\n","norm2 = [[0], [0]] # TODO(you): Update this line to perform an in-memory \n","                   # calculation of a linear regression using the optimized \n","                   # pseudoinverse equation in the place of the [[0], [0]]\n","                   # matrix.\n","\n","calculated_intercept2 = norm2[0][0] \n","calculated_slope2 = norm2[1][0]\n","\n","EPSILON = 0.00001\n","\n","if (abs(SLOPE - calculated_slope2) < EPSILON and\n","    (abs(INTERCEPT - calculated_intercept2)) < EPSILON):\n","  print(\"You win!\")\n","else:\n","  print(\"Try again :(\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i48pOk-KHW3L"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"hhnHS71gkTGG"},"source":["# Exercises\n","\n","For these exercises, we will download a CSV of life expectancies from [GapMinder](https://www.gapminder.org/data/) and create a linear regression predicting life expectancy in the United States."]},{"cell_type":"markdown","metadata":{"id":"TeZpmfYslA0n"},"source":["## Exercise 1: Obtain the Data"]},{"cell_type":"markdown","metadata":{"id":"MAp0fOaingQL"},"source":["Download a CSV of life expectancy data from [GapMinder](https://www.gapminder.org/data/), upload it to this Colab, and read the data into memory using Pandas.\n","\n","Examine the data using describe."]},{"cell_type":"markdown","metadata":{"id":"4k9TCn3KQpVe"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"wzylGqFydG7R"},"source":["# Your code goes here\n","import pandas as pd\n","path = \"/content/life_expectancy_years.csv\"\n","df = pd.read_csv(path)\n","\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CkWhkKTgMGOG"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"hm_yiqt9lkRh"},"source":["## Exercise 2: Inspect the Data"]},{"cell_type":"markdown","metadata":{"id":"Wef2akPdniWy"},"source":["Examine the data using head and/or tail."]},{"cell_type":"markdown","metadata":{"id":"xPk41fIoQ6sv"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"rO2eP1B_dyFA"},"source":["# Your code goes here\n","df.head()\n","df.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h_KGjg5TMOdF"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"HKbB0goxl-gQ"},"source":["## Exercise 3: Preprocess Life Expectancy Column"]},{"cell_type":"markdown","metadata":{"id":"DEYyHO4knkg8"},"source":["Extract the life expectancy values for the United States into a NumPy array. \n","\n","To do this you'll need to find the row that contains data for the United States. When you find that row of data, you'll find the word 'United States' in the first column and then floating point numbers in subsequent columns. The goal of this step is to create a NumPy array containing those numbers, but excluding the first column with the title 'United States'."]},{"cell_type":"markdown","metadata":{"id":"sSyjgiQXRHYC"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"rm_mqNir8HLs"},"source":["import numpy as np\n","us = df[df['country'] == 'United States'].values[:, 1:]\n","us = us.reshape((us.shape[1], 1))\n","us"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-e7VTXN_MRtP"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"VKjiMJUYmPxB"},"source":["## Exercise 4: Create Yearly Data"]},{"cell_type":"markdown","metadata":{"id":"fxaHozJBnnEZ"},"source":["Now we need to create an array of year data from the minimum to the maximum year in the dataset. There are a few ways that this can be done.\n","\n","The column names (except column 0) are the years. You can extract those years into an array, similarly to what you did for life expectancy. Note that the column names are strings, so you'll want to convert them into integers.\n","\n","If no years are missing from the dataset, you can also just use a range function to generate numbers between the min and max years."]},{"cell_type":"markdown","metadata":{"id":"QImI7PELRSmz"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"dpPEWZK-fVl7"},"source":["year_data = df.columns[1:].unique().to_numpy().astype('int')\n","year_data = year_data.reshape(year_data.shape[0], 1)\n","year_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xHJOCRU3NgRi"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"XaAeDllAmeQk"},"source":["## Exercise 5: Plot the Data"]},{"cell_type":"markdown","metadata":{"id":"Av4o6raqnpeT"},"source":["Create a scatterplot of the data."]},{"cell_type":"markdown","metadata":{"id":"R7sBzMhmRejB"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"iY2K1x7Wf-yr"},"source":["import matplotlib.pyplot as plt\n","\n","x = year_data\n","y = us\n","\n","plt.figure(figsize=(8,8))\n","\n","plt.xlabel(\"years\")\n","plt.ylabel(\"age of expectancy\")\n","\n","plt.scatter(x,y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Su5luLDDNiPE"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"iQp6L7K2mj6F"},"source":["## Exercise 6: Subset the Data"]},{"cell_type":"markdown","metadata":{"id":"ygr_3N79nsQu"},"source":["Split off 20% of the data as a test set, and keep the rest for training.\n","\n","To do this it will be useful to create a `DataFrame` and store the years and life expectancy arrays created above as columns in that dataframe.\n","\n","You can then randomize and split the dataframe, or use scikit-learn's built in test/train data splitter."]},{"cell_type":"markdown","metadata":{"id":"JPUqZXnxR5d8"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"j4D8uwmhmqqp"},"source":["# Your code goes here\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(year_data, us, test_size=0.20, random_state=42)\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NFIHbMESNsaw"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"JN_s6eb_mswQ"},"source":["## Exercise 7: Train a Model"]},{"cell_type":"markdown","metadata":{"id":"pV7ZhE6qnumn"},"source":["Use `LinearRegression` in scikit-learn to create a model."]},{"cell_type":"markdown","metadata":{"id":"lDKFaGk4SHMA"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"-H0VAClvOACh"},"source":["# Your code goes here\n","from sklearn.linear_model import LinearRegression\n","\n","lin_reg = LinearRegression()\n","lin_reg.fit(x, y)\n","lin_reg.coef_, lin_reg.intercept_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CbfzTfazOBq5"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"dtFpVNwEnX9Q"},"source":["## Exercise 8: Test Your Model"]},{"cell_type":"markdown","metadata":{"id":"mALMCq0SnwoR"},"source":["Use the test data you put aside to make predictions of life expectancy based on year. Compare the predictions to the actual data by using scikit-learn to calculate the root mean squared error."]},{"cell_type":"markdown","metadata":{"id":"8my8vKLBSZPE"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"3xABv08xnzNg"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3zgvlJJtPRWg"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"yN34XjZpn8YS"},"source":["## Exercise 9: Plot Your Regression"]},{"cell_type":"markdown","metadata":{"id":"6XxLAdoan1J6"},"source":["Create a scatter plot of the full set of life expectancy data. Draw your regression line over the scatterplot."]},{"cell_type":"markdown","metadata":{"id":"CtivIm4GSoVI"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"XJUdILlKoQ4T"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A2FLyo2MPtrp"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"WClC4PzQIXXr"},"source":["## Challenge"]},{"cell_type":"markdown","metadata":{"id":"sJvVUYPmn4i9"},"source":["The [CalCOFI dataset](https://www.kaggle.com/sohier/calcofi/version/2) contains decades of oceanic data. In this exercise, we will use this data to attempt to predict water temperature based on salinity. The exercise is divided into multiple steps, each with a code block after it for your solution."]},{"cell_type":"markdown","metadata":{"id":"Ly-Yql3A7ooA"},"source":["### Student Solution"]},{"cell_type":"markdown","metadata":{"id":"IXJfxu8lKNsg"},"source":["**Acquire the data**\n","\n","The [CalCOFI data](https://www.kaggle.com/sohier/calcofi/version/2) consists of two files, one containing data about *Casts* and the other about *Bottles*. Look at the data files and try to get an understanding of what a cast is and what a bottle is.\n","\n","Find the file that contains temperature and salinity information, download that file, and then upload it to Colab. You'll want to use the zipped version of the file, so that the upload doesn't take too long.\n","\n","Once the file is uploaded, use Python to unzip the file."]},{"cell_type":"code","metadata":{"id":"lcLke7YdP4rf"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NAaW2FpLEe7"},"source":["**Load the data using Pandas**\n","\n","Now that you have an unzipped version of the file, you can load the data into memory using Pandas. Write code to read the file into memory and describe the data table that you created."]},{"cell_type":"code","metadata":{"id":"dTXmyrbBP-dT"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y8My0tHlLhZV"},"source":["**Drop rows with missing data**\n","\n","Looking at the counts for temperature and salinity, you can see that there are some rows with missing data. Remove the rows with missing temperature or salinity data from the dataframe. After you are done, describe the data to make sure that every temperature and salinity row contains data."]},{"cell_type":"code","metadata":{"id":"2FSUUvtuP-4z"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n1pqkRynMBHK"},"source":["**Plot the data**\n","\n","Create a scatterplot of salinity and temperature."]},{"cell_type":"code","metadata":{"id":"Skr58bgBP_cE"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"44I2gHTnMPbh"},"source":["**Shuffle the data**\n","\n","In this exercise, we will split the data into a training set and a test set. Since the data is ordered, we need to shuffle the dataframe before splitting it. Write code to shuffle the dataframe, and look at the data (using `head`, `tail`, or some other means) to make sure that it is shuffled."]},{"cell_type":"code","metadata":{"id":"77VQfHxhP__A"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7WlqxPwqMrsU"},"source":["**Split the data into train/test**\n","\n","For this exercise we'll split the data frame so that 20% of the data is held out for testing, and the remaining data is used for training. Write code to split the data into two dataframes: one for testing and one for training."]},{"cell_type":"code","metadata":{"id":"vGWPiYb0QAZU"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r7kzz9AJNOOQ"},"source":["**Create a linear regression model**\n","\n","Use scikit-learn to fit a linear regression model to your training data."]},{"cell_type":"code","metadata":{"id":"eulLo_ZnQA1d"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5lye2Pf_QUEA"},"source":["**Test your model**\n","\n","Use your test data to make predictions and then find the mean squared error of those predictions vs. the actual measured temperatures for the test data.\n","(scikit-learn has functionality to calculate the mean squared error.)"]},{"cell_type":"code","metadata":{"id":"RagUyVyvQBO9"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mgStCm0HTYT_"},"source":["**Plot your regression line**\n","\n","Create another plot that contains the scatterplot of the salinity and temperatures. Draw the prediction line over the scatterplot."]},{"cell_type":"code","metadata":{"id":"YAStL90PQBj6"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Su3zVHG2ffZw"},"source":["**Dig deeper**\n","\n","The model we built wasn't very good, but we only used one feature. Are there other features or combinations of features that are more predictive of temperature?\n","\n","Measurements were recorded at different depths. Is salinity a good predictor of temperature at any depth range?"]},{"cell_type":"code","metadata":{"id":"tK1898HdHTdh"},"source":["# Your code goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_9anS4V6RRb5"},"source":["---"]}]}